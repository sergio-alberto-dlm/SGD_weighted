# ğŸ”„ Optimized Convergence of Stochastic Gradient Descent by Weighted Averaging

#### Sergio Alberto De Leon MartÃ­nez
#### JosÃ© Ãngel Alejandro Soto

## ğŸ“˜ Theoretical Analysis

### ğŸ’¡ Motivation

We consider the problem of minimizing a function \( f : \mathbb{R}^n \to \mathbb{R} \) expressed as the average of \( m \in \mathbb{N} \) functions \( g_i : \mathbb{R}^n \to \mathbb{R} \):

$$
f(x) = \frac{1}{m} \sum_{i=1}^{m} g_i(x)
$$

When \( m \) is large, or evaluating all \( g_i \) functions is costly, we use **stochastic gradient descent (SGD)**. This approach approximates the gradient in each iteration by:

$$
\begin{align*}
  \nabla f &= \frac{1}{m} \sum_{i=1}^{m} \nabla g_i \\
  &\approx \frac{1}{|S|} \sum_{i \in S} \nabla g_i
\end{align*}
$$

where \( S \) is a random sample from \(\{1, 2, \dots, m\}\).

### ğŸ“ˆ Notation

In the \( k \)-th iteration of the algorithm, we denote:

- \( x_k \): the current solution/vector; \( x_0 \) is user-specified.
- \( \hat{x}_k \): the vector that would be generated by gradient descent.
- \( S_k \): the random sample from \(\{1, 2, \dots, m\}\).
- \( f_k(x_k) = \frac{1}{|S_k|}\sum_{i \in S_k} g_i(x_k) \)
- \( \nabla f_k(x_k) = \frac{1}{|S_k|}\sum_{i \in S_k} \nabla g_i(x_k) \)
- \( \gamma_k \): step size; \( x_{k + 1} = x_k - \gamma_k \nabla_k \)

### ğŸ”¬ Limitation of Analysis

The paper focuses on minimizing strongly convex quadratic functions:

$$
f(x) = \frac{1}{m} \sum_{i=1}^{m} \frac{1}{2} x^T A^{(i)} x + (b^{(i)})^T x + c^{(i)}
$$

Assuming the minimizer is \( x^* = 0 \), the Hessian of \( f \) is a diagonal matrix \( D \) with \( 0 < D_{1, 1} \leq \dots \leq D_{n,n} \). Hence, \( f(x) \) can be simplified to:

$$
f(x) = \frac{1}{m} \sum_{j=1}^{n} \frac{1}{2} a_j x_j^2
$$

with \( a_j = \sum_{i=1}^m A^{(i)}_{j,j} \).

### ğŸ”§ Algorithm Development

Assuming gradient descent is preferable, we define the error of the current approximation as \( \epsilon_k = \nabla f(x_k) - \nabla f_k(x_k) \), with an expected value of zero. The goal is to use different weights and step sizes to reduce variance in a finite number of iterations.

The algorithm results in the weighted average:

$$
\bar{x}_k = \left( \sum_{k=1}^N w_k \right)^{-1} \sum_{k=1}^N w_k x_k
$$

with weights and step sizes defined as:

$$
\begin{align*}
\gamma_k &= c \left( \frac{M}{k + M} \right)^{\alpha}\\
w_k &= k^{\beta}
\end{align*}
$$

for \( \alpha \geq 0, \beta \geq 0, 0 < c \leq \frac{1}{D_{n,n}} \), and \( M \geq 1 \).

### âš™ï¸ Parameter Selection

To minimize the expected value of \( ||\hat{\xi}_k|| \) and achieve convergence, we minimize the variance of:

$$
\kappa(w, \gamma) = \left( \left( \sum_{j=1}^k w_j \right)^{-2} \sum_{i=0}^k ||G_{i,k}||^2 \right)^{\frac{1}{2}}
$$

and the norm:

$$
\tau(w, \gamma) = \left( \sum_{j=1}^k w_j \right)^{-1} \sum_{j=1}^k w_j ||C_{0, j-1}||
$$

This results in a multi-objective optimization problem, managed by minimizing:

$$
r(w, \gamma) = \frac{\tau(w, \gamma) + \mu \kappa(w, \gamma) }{1 + \mu}
$$

ğŸ“š Citation
Optimized Convergence of Stochastic Gradient Descent by Weighted Averaging
Melinda Hagedorn, Florian Jarre

Subjects: Optimization and Control (math.OC)
Cite as: arXiv:2209.14092 [math.OC]
(or arXiv:2209.14092v3 [math.OC] for this version)

https://doi.org/10.48550/arXiv.2209.14092

### ğŸ“ Summary

The parameter selection process is complex and context-dependent. The paper investigates optimal parameters for various iterations and condition numbers, adopting the best-performing parameters from the study.

Happy coding! ğŸ’»âœ¨
